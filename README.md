# coursera_deep_learning_hmwk

### hmwk 1-5 belong to coursera deep learning specialization course 1
#### Neural Network and Deep Learning.
#### They are based on numpy. 
* hmwk 1 (optional) is used to let student have some basic understanding on numpy.
⋅⋅⋅ build sigmoid fuction / gradient of sigmoid
⋅⋅⋅ reshape(np.reshape), vector normalization (np.linalg.norm)
⋅⋅⋅ boardcasting and softmax
⋅⋅⋅ L1 L2 norm
* hmwk2 built a logistic regression on a 209 (m) * 64*64*3 image data set 
⋅⋅* initialization (zeros init because of logistic reg)\\
⋅⋅⋅ basic forward and backward prop
⋅⋅⋅ Gradient descent
⋅⋅⋅ structure/shape of the feeding data. Each col contains a pic,rather than row.
⋅⋅⋅ Viz of cost changing
- hmwk3 buit a *shallow neural net* to do binary classification.
⋅⋅⋅ Two layers
⋅⋅⋅ Loop, forward/ backward chain, parameter update function
⋅⋅⋅ Hidden layer number of unit tunning.
- hmwk4 & hmwk5 buit a *'deep' neural net* to cat/non-cat calssification.
⋅⋅⋅ automatically do loop, forward, backward, cache of A_prev, W, b, grads, parameter update. (based on number of layers)
⋅⋅⋅ relu vs. sigmoid
⋅⋅⋅ homework 5 compared performance between two layers and 5 layers NN.
